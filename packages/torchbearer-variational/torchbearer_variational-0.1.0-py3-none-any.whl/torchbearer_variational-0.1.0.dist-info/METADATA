Metadata-Version: 2.1
Name: torchbearer-variational
Version: 0.1.0
Summary: A variational auto-encoder library for PyTorch using torchbearer
Home-page: https://github.com/pytorchbearer/variational
Author: Ethan Harris
Author-email: ewah1g13@ecs.soton.ac.uk
License: MIT
Download-URL: https://github.com/pytorchbearer/variational/archive/0.1.0.tar.gz
Platform: UNKNOWN
Requires-Python: >=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*
Description-Content-Type: text/markdown
Requires-Dist: torch (>=1.1.0)
Requires-Dist: torchvision (>=0.3.0)
Requires-Dist: torchbearer
Requires-Dist: Pillow
Requires-Dist: numpy

# \[WIP\] torchbearer.variational
A Variational Auto-Encoder library for PyTorch with torchbearer

## Contents
- [About](#about)
- [Installation](#installation)
- [Goals](#goals)

<a name="about"/>

## About

Torchbearer.variational is a companion package to [torchbearer](https://github.com/ecs-vlc/torchbearer) which is intended to
re-implement state of the art models and practices relating to the world of Variational Auto-Encoders (VAEs). The goal
is to provide everything from useful abstractions to complete re-implementations of papers. This is in order to support
both research and teaching / learning regarding VAEs.

<a name="installation"/>

## Installation

TBC

<a name="goals"/>

## Goals

Currently, _variational_ only includes abstractions for simple VAEs and some accompaniments, the next steps are as follows:

- Construct some separate part of the docs for the _variational_ content
- Implement a series of standard models with associated notes pages and example usages
- Implement other divergences not in PyTorch such as MMD, Jensen-Shannon, etc.
- Implement and document tools for sampling the latent spaces of models and producing figures
- Implement other dataloaders not in torchvision and add associated docs

