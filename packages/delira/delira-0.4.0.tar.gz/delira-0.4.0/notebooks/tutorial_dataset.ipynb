{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Dataset Guide (incl. Integration to new API)\n",
    " With Delira v0.3.2 a new dataset API was introduced to allow for more\n",
    " flexibility and add some features. This notebook shows the difference\n",
    " between the new and the old API and provides some examples for newly added\n",
    " features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Overview Old API\n",
    " The old dataset API was based on the assumption that the underlying structure\n",
    " of the data can be described as followed:\n",
    " * root\n",
    "    * sample1\n",
    "         * img1\n",
    "         * img2\n",
    "         * label\n",
    "    * sample2\n",
    "         * img1\n",
    "         * img2\n",
    "         * label\n",
    "    * ...\n",
    "\n",
    "\n",
    " A single sample was constructed from multiple images which are all located in\n",
    " the same subdirectory.\n",
    " The corresponding signature of the `AbstractDataset` was given by\n",
    " `data_path, load_fn, img_extensions, gt_extensions`.\n",
    " While most datasets need a `load_fn` to load a single sample and a\n",
    " `data_path` to the root directory, `img_extensions`and `gt_exntensions`\n",
    " were often unsed.\n",
    " As a consequence a new dataset needed to be created which initialises the\n",
    " unused variables with arbitrary values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Overview New API\n",
    " The new dataset API was refactored to a more general approach where only a\n",
    " `data_path` to the root directory and a `load_fn` for a single sample need\n",
    " to be provided.\n",
    " A simple loading function (`load_fn`) to generate random data independent\n",
    " from the given path might be realized as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_random_data(path: str) -> dict:\n",
    "    \"\"\"Load random data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        path to sample (not used in this example)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        return data inside a dict\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'data': np.random.rand(3, 512, 512),\n",
    "        'label': np.random.randint(0, 10),\n",
    "        'path': path,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " When used with the provided BaseDatasets, the return value of the load\n",
    " function is not limited to dictionaries and might be of any type which can be\n",
    " added to a list with the `append` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### New Datasets\n",
    " Some basic datasets are already implemented inside Delira and should be\n",
    " suitable for most cases. The `BaseCacheDataset` saves all samples inside the\n",
    " RAM and thus can only be used if everything fits inside the memory.\n",
    " ´BaseLazyDataset´ loads the individual samples on time when they are needed,\n",
    " but might lead to slower training due to the additional loading time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delira.data_loading import BaseCacheDataset, BaseLazyDataset\n",
    "\n",
    "\n",
    "# because `load_random_data` does not use the path argument, they can have\n",
    "# arbitrary values in this example\n",
    "paths = list(range(10))\n",
    "\n",
    "# create case dataset\n",
    "cached_set = BaseCacheDataset(paths, load_random_data)\n",
    "\n",
    "# create lazy dataset\n",
    "lazy_set = BaseLazyDataset(paths, load_random_data)\n",
    "\n",
    "# print cached data\n",
    "print(cached_set[0].keys())\n",
    "\n",
    "# print lazy data\n",
    "print(lazy_set[0].keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In the above example a list of multiple paths is used as the `data_path`.\n",
    " `load_fn` is called for every element inside the provided list (can be any\n",
    " iterator). If `data_path` is a single string, it is assumed to be the path\n",
    " to the root directory. In this case, `load_fn`is called for every element\n",
    " inside the root directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Sometimes, a single file/folder contains multiple samples.\n",
    " `BaseExtendCacheDataset` uses the `extend` function to add elements to the\n",
    " internal list. Thus it is assumed that `load_fn` provides an iterable object,\n",
    " where eacht item represents a single data sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `AbstractDataset` is now iterable and can be used directly in combination\n",
    " with for loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cs in cached_set:\n",
    "    print(cs[\"path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## New Utility Function (Integration to new API)\n",
    " The behavior of the old API can be replicated with the `LoadSample`,\n",
    " `LoadSampleLabel`functions. `LoadSample` assumes that all needed images and\n",
    " the label (for a single sample) are located in a directory. Both functions\n",
    " return a dictionary containing the loaded data.\n",
    " `sample_ext` maps keys to iterables. Each iterable defines the names of the\n",
    " images which should be loaded from the directory. ´sample_fn´ is used to load\n",
    " the images which are than stacked inside a single array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delira.data_loading import LoadSample, LoadSampleLabel\n",
    "\n",
    "\n",
    "def load_random_array(path: str):\n",
    "    \"\"\"Return random data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        path to image\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        loaded data\n",
    "    \"\"\"\n",
    "    return np.random.rand(128, 128)\n",
    "\n",
    "\n",
    "# define the function to load a single sample from a directory\n",
    "load_fn = LoadSample(\n",
    "    sample_ext={\n",
    "        # load 3 data channels\n",
    "        'data': ['red.png', 'green.png', 'blue.png'],\n",
    "        # load a singel segmentation channel\n",
    "        'seg': ['seg.png']\n",
    "    },\n",
    "    sample_fn=load_random_array,\n",
    "    # optionally: assign individual keys a datatype\n",
    "    dtype={\"data\": \"float\", \"seg\": \"uint8\"},\n",
    "    # optioanlly: normalize individual samples\n",
    "    normalize=[\"data\"])\n",
    "\n",
    "# Note: in general the function should be called with the path of the\n",
    "# directory where the imags are located\n",
    "sample0 = load_fn(\".\")\n",
    "\n",
    "print(\"data shape: {}\".format(sample0[\"data\"].shape))\n",
    "print(\"segmentation shape: {}\".format(sample0[\"seg\"].shape))\n",
    "print(\"data type: {}\".format(sample0[\"data\"].dtype))\n",
    "print(\"segmentation type: {}\".format(sample0[\"seg\"].dtype))\n",
    "print(\"data min value: {}\".format(sample0[\"data\"].min()))\n",
    "print(\"data max value: {}\".format(sample0[\"data\"].max()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " By default the range is normalized to (-1, 1), but `norm_fn` can be\n",
    " changed to achieve other normalization schemes. Some examples are included\n",
    " in `delira.data_loading.load_utils`.\n",
    "\n",
    " `LoadSampleLabel` takes an additional argument for the label and a function\n",
    " to load a label. This functions can be used in combination with the provided\n",
    " BaseDatasets to replicate (and extend) the old API."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
