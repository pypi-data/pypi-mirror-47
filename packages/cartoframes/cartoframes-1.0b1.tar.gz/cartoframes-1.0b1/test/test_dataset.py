# -*- coding: utf-8 -*-

"""Unit tests for cartoframes.context"""
import unittest
import os
import sys
import json
import warnings
import pandas as pd

from carto.exceptions import CartoException

from cartoframes.context import CartoContext
from cartoframes.data import Dataset
from cartoframes.data.utils import decode_geometry, setting_value_exception
from cartoframes.columns import normalize_name
from cartoframes.geojson import load_geojson
from mocks.dataset_mock import DatasetMock
from mocks.context_mock import ContextMock

from utils import _UserUrlLoader

WILL_SKIP = False
warnings.filterwarnings("ignore")


class TestDataset(unittest.TestCase, _UserUrlLoader):
    """Tests for cartoframes.CARTOframes"""

    def setUp(self):
        if (os.environ.get('APIKEY') is None or
                os.environ.get('USERNAME') is None):
            try:
                creds = json.loads(open('test/secret.json').read())
                self.apikey = creds['APIKEY']
                self.username = creds['USERNAME']
            except:  # noqa: E722
                warnings.warn("Skipping CartoContext tests. To test it, "
                              "create a `secret.json` file in test/ by "
                              "renaming `secret.json.sample` to `secret.json` "
                              "and updating the credentials to match your "
                              "environment.")
                self.apikey = None
                self.username = None
        else:
            self.apikey = os.environ['APIKEY']
            self.username = os.environ['USERNAME']

        # sets skip value
        WILL_SKIP = self.apikey is None or self.username is None  # noqa: F841

        # table naming info
        has_mpl = 'mpl' if os.environ.get('MPLBACKEND') else 'nonmpl'
        has_gpd = 'gpd' if os.environ.get('USE_GEOPANDAS') else 'nongpd'
        pyver = sys.version[0:3].replace('.', '_')
        buildnum = os.environ.get('TRAVIS_BUILD_NUMBER') or 'none'

        test_slug = '{ver}_{num}_{mpl}_{gpd}'.format(
            ver=pyver, num=buildnum, mpl=has_mpl, gpd=has_gpd
        )

        # for writing to carto
        self.test_write_table = normalize_name(
            'cf_test_table_{}'.format(test_slug)
        )

        self.baseurl = self.user_url().format(username=self.username)
        self.cc = CartoContext(base_url=self.baseurl, api_key=self.apikey)

        self.test_geojson = {
            "type": "FeatureCollection",
            "features": [
                {
                    "type": "Feature",
                    "properties": {},
                    "geometry": {
                        "type": "Point",
                        "coordinates": [
                            -3.1640625,
                            42.032974332441405
                        ]
                    }
                }
            ]
        }

        self.tearDown()

    def tearDown(self):
        """restore to original state"""
        tables = (self.test_write_table, )
        sql_drop = 'DROP TABLE IF EXISTS {};'

        if self.apikey and self.baseurl:
            for table in tables:
                try:
                    self.cc.delete(table)
                    self.cc.sql_client.send(sql_drop.format(table))
                except CartoException:
                    warnings.warn('Error deleting tables')

    def test_dataset_constructor_validation_fails_with_table_name_and_query(self):
        table_name = 'fake_table'
        schema = 'fake_schema'
        query = 'select * from fake_table'
        with self.assertRaises(ValueError):
            Dataset(table_name=table_name, schema=schema, query=query)

    def test_dataset_constructor_validation_fails_with_table_name_and_dataframe(self):
        table_name = 'fake_table'
        schema = 'fake_schema'
        df = {}
        with self.assertRaises(ValueError):
            Dataset(table_name=table_name, schema=schema, df=df)

    def test_dataset_constructor_validation_fails_with_table_name_and_geodataframe(self):
        table_name = 'fake_table'
        schema = 'fake_schema'
        gdf = {}
        with self.assertRaises(ValueError):
            Dataset(table_name=table_name, schema=schema, gdf=gdf)

    def test_dataset_constructor_validation_fails_with_query_and_dataframe(self):
        query = 'select * from fake_table'
        df = {}
        with self.assertRaises(ValueError):
            Dataset(query=query, df=df)

    def test_dataset_constructor_validation_fails_with_dataframe_and_geodataframe(self):
        df = {}
        gdf = {}
        with self.assertRaises(ValueError):
            Dataset(df=df, gdf=gdf)

    def test_dataset_from_table(self):
        table_name = 'fake_table'
        dataset = Dataset.from_table(table_name=table_name, context=self.cc)

        self.assertIsInstance(dataset, Dataset)
        self.assertEqual(dataset.table_name, table_name)
        self.assertEqual(dataset._schema, 'public')
        self.assertIsNone(dataset._query)
        self.assertIsNone(dataset._df)
        self.assertIsNone(dataset._gdf)
        self.assertEqual(dataset._cc, self.cc)
        self.assertEqual(dataset._state, Dataset.STATE_REMOTE)

    def test_dataset_from_query(self):
        query = 'SELECT * FROM fake_table'
        dataset = Dataset.from_query(query=query, context=self.cc)

        self.assertIsInstance(dataset, Dataset)
        self.assertEqual(dataset._query, query)
        self.assertIsNone(dataset.table_name)
        self.assertIsNone(dataset._df)
        self.assertIsNone(dataset._gdf)
        self.assertEqual(dataset._cc, self.cc)
        self.assertEqual(dataset._state, Dataset.STATE_REMOTE)

    def test_dataset_from_dataframe(self):
        df = load_geojson(self.test_geojson)
        dataset = Dataset.from_dataframe(df=df)

        self.assertIsInstance(dataset, Dataset)
        self.assertIsNotNone(dataset._df)
        self.assertIsNone(dataset.table_name)
        self.assertIsNone(dataset._query)
        self.assertIsNone(dataset._gdf)
        self.assertIsNone(dataset._cc)
        self.assertEqual(dataset._state, Dataset.STATE_LOCAL)

    def test_dataset_from_geodataframe(self):
        gdf = load_geojson(self.test_geojson)
        dataset = Dataset.from_geodataframe(gdf=gdf)

        self.assertIsInstance(dataset, Dataset)
        self.assertIsNotNone(dataset._gdf)
        self.assertIsNone(dataset.table_name)
        self.assertIsNone(dataset._query)
        self.assertIsNone(dataset._df)
        self.assertIsNone(dataset._cc)
        self.assertEqual(dataset._state, Dataset.STATE_LOCAL)

    def test_dataset_from_geojson(self):
        geojson = self.test_geojson
        dataset = Dataset.from_geojson(geojson=geojson)

        self.assertIsInstance(dataset, Dataset)
        self.assertIsNotNone(dataset._gdf)
        self.assertIsNone(dataset.table_name)
        self.assertIsNone(dataset._query)
        self.assertIsNone(dataset._df)
        self.assertIsNone(dataset._cc)
        self.assertEqual(dataset._state, Dataset.STATE_LOCAL)

    def test_dataset_upload_validation_fails_only_with_table_name(self):
        table_name = 'fake_table'
        dataset = Dataset.from_table(table_name=table_name, context=self.cc)
        err_msg = 'Nothing to upload. We need data in a DataFrame or GeoDataFrame or a query to upload data to CARTO.'
        with self.assertRaises(ValueError, msg=err_msg):
            dataset.upload()

    def test_dataset_upload_validation_query_fails_without_table_name(self):
        query = 'SELECT 1'
        dataset = Dataset.from_query(query=query, context=self.cc)
        with self.assertRaises(ValueError, msg='You should provide a table_name and context to upload data.'):
            dataset.upload()

    def test_dataset_upload_validation_df_fails_without_table_name_and_context(self):
        df = load_geojson(self.test_geojson)
        dataset = Dataset.from_dataframe(df=df)
        with self.assertRaises(ValueError, msg='You should provide a table_name and context to upload data.'):
            dataset.upload()

    def test_dataset_upload_validation_df_fails_without_context(self):
        df = load_geojson(self.test_geojson)
        dataset = Dataset.from_dataframe(df=df)
        with self.assertRaises(ValueError, msg='You should provide a table_name and context to upload data.'):
            dataset.upload(table_name=self.test_write_table)

    @unittest.skipIf(WILL_SKIP, 'no carto credentials, skipping this test')
    def test_dataset_upload_into_existing_table_fails_without_replace_property(self):
        query = 'SELECT 1'
        dataset = Dataset.from_query(query=query, context=self.cc)
        dataset.upload(table_name=self.test_write_table)
        err_msg = ('Table with name {t} and schema {s} already exists in CARTO. Please choose a different `table_name`'
                   'or use if_exists="replace" to overwrite it').format(t=self.test_write_table, s='public')
        with self.assertRaises(CartoException, msg=err_msg):
            dataset.upload(table_name=self.test_write_table)
        dataset.upload(table_name=self.test_write_table, if_exists=Dataset.REPLACE)

    def test_dataset_upload_validation_fails_with_query_and_append(self):
        query = 'SELECT 1'
        dataset = Dataset.from_query(query=query, context=self.cc)
        err_msg = 'Error using append with a query Dataset. It is not possible to append data to a query'
        with self.assertRaises(CartoException, msg=err_msg):
            dataset.upload(table_name=self.test_write_table, if_exists=Dataset.APPEND)

    @unittest.skipIf(WILL_SKIP, 'no carto credentials, skipping this test')
    def test_dataset_download_validations(self):
        self.assertNotExistsTable(self.test_write_table)

        df = load_geojson(self.test_geojson)
        dataset = Dataset.from_dataframe(df=df)
        error_msg = 'You should provide a context and a table_name or query to download data.'
        with self.assertRaises(ValueError, msg=error_msg):
            dataset.download()

        query = 'SELECT 1 as fakec'
        dataset = Dataset.from_query(query=query, context=self.cc)
        dataset.upload(table_name=self.test_write_table)

        dataset._table_name = 'non_used_table'
        df = dataset.download()
        self.assertEqual('fakec' in df.columns, True)

        dataset = Dataset.from_table(table_name=self.test_write_table, context=self.cc)
        df = dataset.download()
        self.assertEqual('fakec' in df.columns, True)

    def test_dataset_download_and_upload(self):
        self.assertNotExistsTable(self.test_write_table)

        query = 'SELECT 1 as fakec'
        dataset = Dataset.from_query(query=query, context=self.cc)
        dataset.upload(table_name=self.test_write_table)

        dataset = Dataset.from_table(table_name=self.test_write_table, context=self.cc)
        dataset.download()
        dataset.upload(table_name=self.test_write_table, if_exists=Dataset.REPLACE)

    def test_dataset_download_bool_null(self):
        self.assertNotExistsTable(self.test_write_table)

        query = 'SELECT * FROM (values (true, true), (false, false), (false, null)) as x(fakec_bool, fakec_bool_null)'
        dataset = Dataset.from_query(query=query, context=self.cc)
        dataset.upload(table_name=self.test_write_table)

        dataset = Dataset.from_table(table_name=self.test_write_table, context=self.cc)
        df = dataset.download()

        self.assertEqual(df['fakec_bool'].dtype, 'bool')
        self.assertEqual(df['fakec_bool_null'].dtype, 'object')
        self.assertEqual(list(df['fakec_bool']), [True, False, False])
        self.assertEqual(list(df['fakec_bool_null']), [True, False, None])

    @unittest.skipIf(WILL_SKIP, 'no carto credentials, skipping this test')
    def test_dataset_write_points_dataset(self):
        self.assertNotExistsTable(self.test_write_table)

        from cartoframes.examples import read_mcdonalds_nyc
        df = read_mcdonalds_nyc(limit=100)
        dataset = Dataset.from_dataframe(df).upload(table_name=self.test_write_table, context=self.cc)
        self.test_write_table = dataset.table_name

        result = self.cc.sql_client.send('SELECT * FROM {} WHERE the_geom IS NOT NULL'.format(self.test_write_table))
        self.assertEqual(result['total_rows'], 100)

    @unittest.skipIf(WILL_SKIP, 'no carto credentials, skipping this test')
    def test_dataset_write_lines_dataset(self):
        self.assertNotExistsTable(self.test_write_table)

        from cartoframes.examples import read_ne_50m_graticules_15
        df = read_ne_50m_graticules_15()
        dataset = Dataset.from_dataframe(df).upload(table_name=self.test_write_table, context=self.cc)
        self.test_write_table = dataset.table_name

        result = self.cc.sql_client.send('SELECT * FROM {} WHERE the_geom IS NOT NULL'.format(self.test_write_table))
        self.assertEqual(result['total_rows'], 35)

    @unittest.skipIf(WILL_SKIP, 'no carto credentials, skipping this test')
    def test_dataset_write_polygons_dataset(self):
        self.assertNotExistsTable(self.test_write_table)

        from cartoframes.examples import read_brooklyn_poverty
        df = read_brooklyn_poverty()
        dataset = Dataset.from_dataframe(df).upload(table_name=self.test_write_table, context=self.cc)
        self.test_write_table = dataset.table_name

        result = self.cc.sql_client.send('SELECT * FROM {} WHERE the_geom IS NOT NULL'.format(self.test_write_table))
        self.assertEqual(result['total_rows'], 2049)

    @unittest.skipIf(WILL_SKIP, 'no carto credentials, skipping this test')
    def test_dataset_write_lnglat_dataset(self):
        self.assertNotExistsTable(self.test_write_table)

        from cartoframes.examples import read_taxi
        df = read_taxi(limit=100)
        lnglat = ('dropoff_longitude', 'dropoff_latitude')
        dataset = Dataset.from_dataframe(df).upload(
            with_lnglat=lnglat, table_name=self.test_write_table, context=self.cc)
        self.test_write_table = dataset.table_name

        self.assertExistsTable(self.test_write_table)

        result = self.cc.sql_client.send('SELECT * FROM {} WHERE the_geom IS NOT NULL'.format(self.test_write_table))
        self.assertEqual(result['total_rows'], 100)

    @unittest.skipIf(WILL_SKIP, 'no carto credentials, skipping this test')
    def test_dataset_write_null_geometry_column(self):
        self.assertNotExistsTable(self.test_write_table)

        from cartoframes.examples import read_taxi
        df = read_taxi(limit=100)
        dataset = Dataset.from_dataframe(df).upload(table_name=self.test_write_table, context=self.cc)
        self.test_write_table = dataset.table_name

        self.assertExistsTable(self.test_write_table)

        result = self.cc.sql_client.send('SELECT * FROM {} WHERE the_geom IS NULL'.format(self.test_write_table))
        self.assertEqual(result['total_rows'], 100)

    @unittest.skipIf(WILL_SKIP, 'no carto credentials, skipping this test')
    def test_dataset_write_with_different_geometry_column(self):
        self.assertNotExistsTable(self.test_write_table)

        from cartoframes.examples import read_brooklyn_poverty
        df = read_brooklyn_poverty()
        df.rename(columns={'the_geom': 'geometry'}, inplace=True)
        dataset = Dataset.from_dataframe(df).upload(table_name=self.test_write_table, context=self.cc)
        self.test_write_table = dataset.table_name

        self.assertExistsTable(self.test_write_table)

        result = self.cc.sql_client.send('SELECT * FROM {} WHERE the_geom IS NOT NULL'.format(self.test_write_table))
        self.assertEqual(result['total_rows'], 2049)

    @unittest.skipIf(WILL_SKIP, 'no carto credentials, skipping this test')
    def test_dataset_write_with_different_geom_column(self):
        self.assertNotExistsTable(self.test_write_table)

        from cartoframes.examples import read_brooklyn_poverty
        df = read_brooklyn_poverty()

        df.rename(columns={'the_geom': 'geom'}, inplace=True)
        dataset = Dataset.from_dataframe(df).upload(table_name=self.test_write_table, context=self.cc)
        self.test_write_table = dataset.table_name

        self.assertExistsTable(self.test_write_table)

        result = self.cc.sql_client.send('SELECT * FROM {} WHERE the_geom IS NOT NULL'.format(self.test_write_table))
        self.assertEqual(result['total_rows'], 2049)

    @unittest.skipIf(WILL_SKIP, 'no carto credentials, skipping this test')
    def test_dataset_write_geopandas(self):
        self.assertNotExistsTable(self.test_write_table)

        from cartoframes.examples import read_taxi
        import shapely
        import geopandas as gpd
        df = read_taxi(limit=50)
        df.drop(['the_geom'], axis=1, inplace=True)
        gdf = gpd.GeoDataFrame(df.drop(['dropoff_longitude', 'dropoff_latitude'], axis=1),
                               crs={'init': 'epsg:4326'},
                               geometry=[shapely.geometry.Point(xy) for xy in
                                         zip(df.dropoff_longitude, df.dropoff_latitude)])

        # TODO: use from_geodataframe
        dataset = Dataset.from_dataframe(gdf).upload(table_name=self.test_write_table, context=self.cc)
        self.test_write_table = dataset.table_name

        self.assertExistsTable(self.test_write_table)

        result = self.cc.sql_client.send('SELECT * FROM {} WHERE the_geom IS NOT NULL'.format(self.test_write_table))
        self.assertEqual(result['total_rows'], 50)

    @unittest.skipIf(WILL_SKIP, 'no carto credentials, skipping this test')
    def test_dataset_write_wkt(self):
        self.assertNotExistsTable(self.test_write_table)

        from cartoframes.examples import read_taxi
        df = read_taxi(limit=50)
        df['the_geom'] = df.apply(lambda x: 'POINT ({x} {y})'
                                  .format(x=x['dropoff_longitude'], y=x['dropoff_latitude']), axis=1)
        dataset = Dataset.from_dataframe(df).upload(table_name=self.test_write_table, context=self.cc)
        self.test_write_table = dataset.table_name

        self.assertExistsTable(self.test_write_table)

        result = self.cc.sql_client.send('SELECT * FROM {} WHERE the_geom IS NOT NULL'.format(self.test_write_table))
        self.assertEqual(result['total_rows'], 50)

    @unittest.skipIf(WILL_SKIP, 'no carto credentials, skipping this test')
    def test_dataset_write_if_exists_fail_by_default(self):
        self.assertNotExistsTable(self.test_write_table)

        from cartoframes.examples import read_brooklyn_poverty
        df = read_brooklyn_poverty()
        dataset = Dataset.from_dataframe(df).upload(table_name=self.test_write_table, context=self.cc)
        self.test_write_table = dataset.table_name

        err_msg = ('Table with name {t} and schema {s} already exists in CARTO. Please choose a different `table_name`'
                   'or use if_exists="replace" to overwrite it').format(t=self.test_write_table, s='public')
        with self.assertRaises(CartoException, msg=err_msg):
            dataset = Dataset.from_dataframe(df).upload(table_name=self.test_write_table, context=self.cc)

        self.assertExistsTable(self.test_write_table)

        result = self.cc.sql_client.send('SELECT * FROM {} WHERE the_geom IS NOT NULL'.format(self.test_write_table))
        self.assertEqual(result['total_rows'], 2049)

    @unittest.skipIf(WILL_SKIP, 'no carto credentials, skipping this test')
    def test_dataset_write_if_exists_append(self):
        from cartoframes.examples import read_brooklyn_poverty
        df = read_brooklyn_poverty()
        dataset = Dataset.from_dataframe(df).upload(table_name=self.test_write_table, context=self.cc)
        self.test_write_table = dataset.table_name

        dataset = Dataset.from_dataframe(df).upload(
            if_exists=Dataset.APPEND, table_name=self.test_write_table, context=self.cc)

        self.assertExistsTable(self.test_write_table)

        result = self.cc.sql_client.send('SELECT * FROM {} WHERE the_geom IS NOT NULL'.format(self.test_write_table))
        self.assertEqual(result['total_rows'], 2049 * 2)

    @unittest.skipIf(WILL_SKIP, 'no carto credentials, skipping this test')
    def test_dataset_write_if_exists_replace(self):
        from cartoframes.examples import read_brooklyn_poverty
        df = read_brooklyn_poverty()
        dataset = Dataset.from_dataframe(df).upload(table_name=self.test_write_table, context=self.cc)
        self.test_write_table = dataset.table_name

        dataset = Dataset.from_dataframe(df).upload(
            if_exists=Dataset.REPLACE, table_name=self.test_write_table, context=self.cc)

        self.assertExistsTable(self.test_write_table)

        result = self.cc.sql_client.send('SELECT * FROM {} WHERE the_geom IS NOT NULL'.format(self.test_write_table))
        self.assertEqual(result['total_rows'], 2049)

    def test_dataset_schema_from_parameter(self):
        schema = 'fake_schema'
        dataset = Dataset.from_table(table_name='fake_table', schema=schema, context=self.cc)
        self.assertEqual(dataset._schema, schema)

    def test_dataset_schema_from_non_org_context(self):
        dataset = Dataset.from_table(table_name='fake_table', context=self.cc)
        self.assertEqual(dataset._schema, 'public')

    def test_dataset_schema_from_org_context(self):
        username = 'fake_username'

        class FakeCreds():
            def username(self):
                return username

        class FakeContext():
            def __init__(self):
                self.is_org = True
                self.creds = FakeCreds()

            def get_default_schema(self):
                return username

        dataset = Dataset.from_table(table_name='fake_table', context=FakeContext())
        self.assertEqual(dataset._schema, username)

    def test_decode_geometry(self):
        # Point (0, 0) without SRID
        ewkb = '010100000000000000000000000000000000000000'
        decoded_geom = decode_geometry(ewkb)
        self.assertEqual(decoded_geom.wkt, 'POINT (0 0)')
        self.assertIsNone(decode_geometry(None))

    # FIXME does not work in python 2.7 (COPY stucks and blocks the table, fix after
    # https://github.com/CartoDB/CartoDB-SQL-API/issues/579 is fixed)
    # @unittest.skipIf(WILL_SKIP, 'no carto credentials, skipping this test')
    # def test_dataset_write_with_encoding(self):
    #     df = pd.DataFrame({'vals': [1, 2], 'strings': ['a', 'ô']})
    #     dataset = self.cc.write(df, self.test_write_table)
    #     self.test_write_table = dataset.table_name

    #     self.assertExistsTable(self.test_write_table)

    def assertExistsTable(self, table_name):
        resp = self.cc.sql_client.send('''
            SELECT *
            FROM {table}
            LIMIT 0
            '''.format(table=table_name))
        self.assertIsNotNone(resp)

    def assertNotExistsTable(self, table_name):
        try:
            self.cc.sql_client.send('''
                SELECT *
                FROM {table}
                LIMIT 0
                '''.format(table=table_name))
        except CartoException as e:
            self.assertTrue('relation "{}" does not exist'.format(table_name) in str(e))


class TestDatasetInfo(unittest.TestCase):
    def setUp(self):
        self.username = 'fake_username'
        self.api_key = 'fake_api_key'
        self.context = ContextMock(username=self.username, api_key=self.api_key)

    def test_dataset_get_privacy_from_new_table(self):
        query = 'SELECT 1'
        dataset = DatasetMock.from_query(query=query, context=self.context)
        dataset.upload(table_name='fake_table')
        self.assertEqual(dataset.dataset_info.privacy, Dataset.PRIVATE)

    def test_dataset_get_privacy_from_not_sync(self):
        query = 'SELECT 1'
        dataset = DatasetMock.from_query(query=query, context=self.context)
        error_msg = ('We can not extract Dataset info from a query. Use `Dataset.from_table()` method '
                     'to get or modify the info from a CARTO table.')
        with self.assertRaises(CartoException, msg=error_msg):
            dataset.dataset_info

    def test_dataset_set_privacy_to_new_table(self):
        query = 'SELECT 1'
        dataset = DatasetMock.from_query(query=query, context=self.context)
        dataset.upload(table_name='fake_table')
        dataset.update_dataset_info(privacy=Dataset.PUBLIC)
        self.assertEqual(dataset.dataset_info.privacy, Dataset.PUBLIC)

    def test_dataset_set_privacy_with_wrong_parameter(self):
        query = 'SELECT 1'
        dataset = DatasetMock.from_query(query=query, context=self.context)
        dataset.upload(table_name='fake_table')
        wrong_privacy = 'wrong_privacy'
        error_msg = 'Wrong privacy. The privacy: {p} is not valid. You can use: {o1}, {o2}, {o3}'.format(
            p=wrong_privacy, o1=Dataset.PRIVATE, o2=Dataset.PUBLIC, o3=Dataset.LINK)
        with self.assertRaises(ValueError, msg=error_msg):
            dataset.update_dataset_info(privacy=wrong_privacy)

    def test_dataset_info_should_work_from_table(self):
        table_name = 'fake_table'
        dataset = DatasetMock.from_table(table_name=table_name, context=self.context)
        self.assertEqual(dataset.dataset_info.privacy, Dataset.PRIVATE)

    def test_dataset_info_props_are_private(self):
        table_name = 'fake_table'
        dataset = DatasetMock.from_table(table_name=table_name, context=self.context)
        dataset_info = dataset.dataset_info
        self.assertEqual(dataset_info.privacy, Dataset.PRIVATE)
        privacy = Dataset.PUBLIC
        error_msg = str(setting_value_exception('privacy', privacy))
        with self.assertRaises(CartoException, msg=error_msg):
            dataset_info.privacy = privacy
        self.assertEqual(dataset_info.privacy, Dataset.PRIVATE)


class TestDatasetUnit(unittest.TestCase, _UserUrlLoader):
    """Unit tests for cartoframes.Dataset"""

    def test_rows(self):
        df = pd.DataFrame.from_dict({'test': [True, [1, 2]]})
        ds = Dataset.from_dataframe(df)
        rows = ds._rows(ds.dataframe, ['test'], None, '')

        self.assertEqual(list(rows), [b'True|\n', b'[1, 2]|\n'])

    def test_rows_null(self):
        df = pd.DataFrame.from_dict({'test': [None, [None, None]]})
        ds = Dataset.from_dataframe(df)
        rows = ds._rows(ds.dataframe, ['test'], None, '')

        self.assertEqual(list(rows), [b'|\n', b'|\n'])
