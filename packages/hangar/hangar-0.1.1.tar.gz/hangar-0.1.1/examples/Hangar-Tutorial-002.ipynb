{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Checkouts, Branching, & Merging\n",
    "\n",
    "This section deals with navigating repository history, creating & merging branches, and understanding conflicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating A Branch\n",
    "\n",
    "The hangar workflow is intended to mimic common `git` workflows in which small incremental changes are made and committed on dedicated `topic` branches. After the `topic` has been adequatly set, `topic` branch is `merged` into a seperate branch (commonly refered to as `master`, though it need not be the actual branch named `\"master\"`), where well vetted and more permenant changes are kept. \n",
    "\n",
    "    Create Branch -> Checkout Branch -> Make Changes -> Commit\n",
    "\n",
    "Let's initialize a new repository and see how branching works in Hangar\n",
    "\n",
    "<!-- However, unlike GIT, remember that it is not possible to make changes in a DETACHED HEAD state. Hangar enforces the requirement that all work is performed at the tip of a branch. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hangar import Repository\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = Repository(path='/Users/rick/projects/tensorwerk/hangar/dev/mnist/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hangar Repo initialized at: /Users/rick/projects/tensorwerk/hangar/dev/mnist/__hangar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/rick/projects/tensorwerk/hangar/dev/mnist/__hangar'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo.init(user_name='Rick Izzo', user_email='rick@tensorwerk.com', remove_old=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a repository is first initialized, it has no history, no commits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo.log() # -> returns None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the repository is essentially empty at this point in time, there is one thing which is present: A branch with the name: `\"master\"`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['master']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo.list_branch_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `\"master\"` branch is the branch we make our first commit on; until we do, the repository is in a semi-unstable state, and will generally flat out refuse to perform otherwise standard operations/behaviors. \n",
    "\n",
    "Since the only option available at this point in time is to create a write-enabled checkout of this `\"master\"` branch so we can add data and make a commit, let's do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = repo.checkout(write=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, there are no datasets or metadata samples recorded in the checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of metadata keys: 0\n",
      "number of datasets: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'number of metadata keys: {len(co.metadata)}')\n",
    "print(f'number of datasets: {len(co.datasets)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a dummy array just to put something in the repository, and we will commit & close the checkout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Specification:: Name: `dummy_dataset`, Initialization style: `prototype`, Shape: `(10,)`, DType: `uint16`, Samples Named: `True`, Variable Shape: `False`, Max Shape: `(10,)`\n",
      "Dataset Initialized: `dummy_dataset`\n",
      "Commit operation requested with message: first commit with a single sample added to a dummy dataset\n",
      "(288, 222, 288)\n",
      "removing all stage hash records\n",
      "Commit completed. Commit hash: b21ebbeeece723bf7aa2157eb2e8742a043df7d0\n",
      "writer checkout of master closed\n"
     ]
    }
   ],
   "source": [
    "dummy = np.arange(10, dtype=np.uint16)\n",
    "dset = co.datasets.init_dataset(name='dummy_dataset', prototype=dummy)\n",
    "dset['0'] = dummy\n",
    "initialCommitHash = co.commit('first commit with a single sample added to a dummy dataset')\n",
    "co.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we check the history now, we can see our first commit hash, and that it is labeled with the branch name `\"master\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* b21ebbeeece723bf7aa2157eb2e8742a043df7d0 (\u001b[1;31mmaster\u001b[m) : first commit with a single sample added to a dummy dataset\n"
     ]
    }
   ],
   "source": [
    "repo.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now our repository contains:\n",
    "- A commit: a fully independent description of the entire repository state as it existed at some point in time. A commit is identified by a `commit_hash`\n",
    "- A branch: a label pointing to a particular `commit` / `commit_hash`\n",
    "\n",
    "Once committed, it is not possible to remove, modify, or otherwise tamper with the contents of a commit in any way. It is a permenant record, which Hangar has no method to change once written to disk. \n",
    "\n",
    "In addition, as a `commit_hash` is not only calculated from the `commit`'s contents, but from the `commit_hash` of its parents (more on this to follow), knowing a single top-level `commit_hash` allows us to verify the integrity of the entire repository history. This fundumental behavior holds even in cases of disk-corruption or malicious use.\n",
    "\n",
    "### All about Checkouts\n",
    "\n",
    "**Checking out a branch/commit for reading:** is the process of retriving records describing repository state at some point in time, and setting up access to the referenced data. \n",
    "\n",
    "- Any number of read checkout processes can operate on a repository (on any number of commits) at the same time.\n",
    "\n",
    "**Checking out a branch for writing:** is the process of setting up a (mutable) `staging area` to temporarily gather record references / data before all changes have been made and the content's of the staging area are `committed` in a new `commit`\n",
    "\n",
    "- Only one write-enabled checkout can ever be operating in a repository at a time\n",
    "- When initially creating the checkout, the `staging area` is not actually \"empty\". Instead, it has the full contents of the last `commit` referenced by a branch's `HEAD`. These records can be removed/mutated/added to in any way to form the next `commit`. The new `commit` retains a permenant reference identifying the previous `HEAD` `commit` was used as it's base `staging area`\n",
    "- On commit, the branch which was checked out has it's `HEAD` pointer value updated to the new `commit`'s `commit_hash`. A write-enabled checkout starting from the same branch will now use that `commit`'s record content as the base for it's `staging area`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A branch must always have a `name` and a `base_commit`. \n",
    "\n",
    "However, If no `base_commit`  is specified, the current writer branch `HEAD` `commit` is used as the `base_commit` hash for the branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_1 = repo.create_branch(branch_name='testbranch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'testbranch'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branch_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "viewing the log, we see that a new branch named: `testbranch` is pointing to our initial commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branch names: ['master', 'testbranch'] \n",
      "\n",
      "* b21ebbeeece723bf7aa2157eb2e8742a043df7d0 (\u001b[1;31mmaster\u001b[m) (\u001b[1;31mtestbranch\u001b[m) : first commit with a single sample added to a dummy dataset\n"
     ]
    }
   ],
   "source": [
    "print(f'branch names: {repo.list_branch_names()} \\n')\n",
    "repo.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If instead, we do actually specify the base commit (with a different branch name) we see we do actually get a third branch. pointing to the same commit as `\"master\"` and `\"testbranch\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_2 = repo.create_branch(branch_name='new', base_commit=initialCommitHash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branch_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* b21ebbeeece723bf7aa2157eb2e8742a043df7d0 (\u001b[1;31mmaster\u001b[m) (\u001b[1;31mnew\u001b[m) (\u001b[1;31mtestbranch\u001b[m) : first commit with a single sample added to a dummy dataset\n"
     ]
    }
   ],
   "source": [
    "repo.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making changes on a branch\n",
    "\n",
    "Let's make some changes on the `\"new\"` branch to see how things might change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = repo.checkout(write=True, branch_name='new')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data we added previously is still here (`dummy` dataset containing one sample labeled `0`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " Hangar Datasets                \n",
       "     Writeable: True                \n",
       "     Dataset Names:                \n",
       "       - dummy_dataset"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " Hangar DatasetDataWriter                 \n",
       "    Dataset Name     : dummy_dataset                \n",
       "    Schema UUID      : d82cddc07e0211e9a08a8c859047adef                \n",
       "    Schema Hash      : 43edf7aa314c                \n",
       "    Variable Shape   : False                \n",
       "    (max) Shape      : (10,)                \n",
       "    Datatype         : <class 'numpy.uint16'>                \n",
       "    Named Samples    : True                \n",
       "    Access Mode      : a                \n",
       "    Num Samples      : 1\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.datasets['dummy_dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.datasets['dummy_dataset']['0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add another sample to the `dummy_dataset` called `1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(10, dtype=np.uint16)\n",
    "# let's increment values so that `0` and `1` aren't set to the same thing\n",
    "arr += 1  \n",
    "\n",
    "co.datasets['dummy_dataset']['1'] = arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in this checkout, there are indeed, two samples in the `dummy_dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(co.datasets['dummy_dataset'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all, let's commit this and be done with this branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commit operation requested with message: commit on `new` branch adding a sample to dummy_dataset\n",
      "(350, 255, 350)\n",
      "removing all stage hash records\n",
      "Commit completed. Commit hash: 0cdd8c833f654d18ddc2b089fabee93c32c9c155\n",
      "writer checkout of new closed\n"
     ]
    }
   ],
   "source": [
    "co.commit('commit on `new` branch adding a sample to dummy_dataset')\n",
    "co.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How do changes appear when made on a branch?\n",
    "\n",
    "If we look at the log, we see that the branch we were on (`new`) is a commit ahead of `master` and `testbranch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 0cdd8c833f654d18ddc2b089fabee93c32c9c155 (\u001b[1;31mnew\u001b[m) : commit on `new` branch adding a sample to dummy_dataset\n",
      "* b21ebbeeece723bf7aa2157eb2e8742a043df7d0 (\u001b[1;31mmaster\u001b[m) (\u001b[1;31mtestbranch\u001b[m) : first commit with a single sample added to a dummy dataset\n"
     ]
    }
   ],
   "source": [
    "repo.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meaning is exactally what one would intuit. we made some changes, they were reflected on the `new` branch, but the `master` and `testbranch` branches were not impacted at all, nor were any of the commits!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging (Part 1) Fast-Forward Merges\n",
    "\n",
    "Say we like the changes we made on the `new` branch so much that we want them to be included into our `master` branch! How do we make this happen for this scenario??\n",
    "\n",
    "Well, the history between the `HEAD` of the `\"new\"` and the `HEAD` of the `\"master\"` branch is perfectly linear. In fact, when we began making changes on `\"new\"`, our staging area was *identical* to what the `\"master\"` `HEAD` commit references are right now! \n",
    "\n",
    "If you'll remember that a branch is just a pointer which assigns some `name` to a `commit_hash`, it becomes apparent that a merge in this case really doesn't involve any work at all. With a linear history between `\"master\"` and `\"new\"`, any `commits` exsting along the path between the `HEAD` of `\"new\"` and `\"master\"` are the only changes which are introduced, and we can be sure that this is the only view of the data records which can exist!\n",
    "\n",
    "What this means in practice is that for this type of merge, we can just update the `HEAD` of `\"master\"` to point to the `\"HEAD\"` of `\"new\"`, and the merge is complete. \n",
    "\n",
    "This situation is reffered to as a **Fast Forward (FF) Merge**. A FF merge is safe to perform any time a linear history lies between the `\"HEAD\"` of some `topic` and `base` branch, regardless of how many commits or changes which were introduced.\n",
    "\n",
    "For other situations, a more complicated **Three Way Merge** is required. This merge method will be explained a bit more later in this tutorail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = repo.checkout(write=True, branch_name='master')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing the Merge\n",
    "\n",
    "In practice, you'll never need to know the details of the merge theory explained above (or even remember it exists). Hangar automatically figures out which merge algorithms should be used and then performes whatever calculations are needed to compute the results. \n",
    "\n",
    "As a user, merging in Hangar is a one-liner!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Fast-Forward Merge Stratagy\n",
      "removing all stage hash records\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0cdd8c833f654d18ddc2b089fabee93c32c9c155'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.merge(message='message for commit (not used for FF merge)', dev_branch='new')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check the log!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 0cdd8c833f654d18ddc2b089fabee93c32c9c155 (\u001b[1;31mmaster\u001b[m) (\u001b[1;31mnew\u001b[m) : commit on `new` branch adding a sample to dummy_dataset\n",
      "* b21ebbeeece723bf7aa2157eb2e8742a043df7d0 (\u001b[1;31mtestbranch\u001b[m) : first commit with a single sample added to a dummy dataset\n"
     ]
    }
   ],
   "source": [
    "repo.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'master'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.branch_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0cdd8c833f654d18ddc2b089fabee93c32c9c155'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.commit_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " Hangar DatasetDataWriter                 \n",
       "    Dataset Name     : dummy_dataset                \n",
       "    Schema UUID      : d82cddc07e0211e9a08a8c859047adef                \n",
       "    Schema Hash      : 43edf7aa314c                \n",
       "    Variable Shape   : False                \n",
       "    (max) Shape      : (10,)                \n",
       "    Datatype         : <class 'numpy.uint16'>                \n",
       "    Named Samples    : True                \n",
       "    Access Mode      : a                \n",
       "    Num Samples      : 2\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.datasets['dummy_dataset']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you can see, everything is as it should be!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writer checkout of master closed\n"
     ]
    }
   ],
   "source": [
    "co.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a changes to introduce diverged histories\n",
    "\n",
    "Let's now go back to our `\"testbranch\"` branch and make some changes there so we can see what happens when changes don't follow a linear history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = repo.checkout(write=True, branch_name='testbranch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " Hangar Datasets                \n",
       "     Writeable: True                \n",
       "     Dataset Names:                \n",
       "       - dummy_dataset"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " Hangar DatasetDataWriter                 \n",
       "    Dataset Name     : dummy_dataset                \n",
       "    Schema UUID      : d82cddc07e0211e9a08a8c859047adef                \n",
       "    Schema Hash      : 43edf7aa314c                \n",
       "    Variable Shape   : False                \n",
       "    (max) Shape      : (10,)                \n",
       "    Datatype         : <class 'numpy.uint16'>                \n",
       "    Named Samples    : True                \n",
       "    Access Mode      : a                \n",
       "    Num Samples      : 1\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.datasets['dummy_dataset']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by mutating sample `0` in `dummy_dataset` to a different value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_dset = co.datasets['dummy_dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50, 51, 52, 53, 54, 55, 56, 57, 58, 59], dtype=uint16)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_arr = dummy_dset['0']\n",
    "new_arr = old_arr + 50\n",
    "new_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_dset['0'] = new_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's make a commit here, then add some metadata and make a new commit (all on the `testbranch` branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commit operation requested with message: mutated sample `0` of `dummy_dataset` to new value\n",
      "(288, 222, 288)\n",
      "removing all stage hash records\n",
      "Commit completed. Commit hash: 4fdb96afed4ec62e9fc80328abccae6bf6774fea\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4fdb96afed4ec62e9fc80328abccae6bf6774fea'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.commit('mutated sample `0` of `dummy_dataset` to new value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 4fdb96afed4ec62e9fc80328abccae6bf6774fea (\u001b[1;31mtestbranch\u001b[m) : mutated sample `0` of `dummy_dataset` to new value\n",
      "* b21ebbeeece723bf7aa2157eb2e8742a043df7d0 : first commit with a single sample added to a dummy dataset\n"
     ]
    }
   ],
   "source": [
    "repo.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "co.metadata['hello'] = 'world'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commit operation requested with message: added hellow world metadata\n",
      "(348, 260, 348)\n",
      "removing all stage hash records\n",
      "Commit completed. Commit hash: ce8a9198d638b8fd89a175486d21d2bb2efabc91\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ce8a9198d638b8fd89a175486d21d2bb2efabc91'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.commit('added hellow world metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writer checkout of testbranch closed\n"
     ]
    }
   ],
   "source": [
    "co.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at our history how, we see that none of the original branches reference our first commit anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* ce8a9198d638b8fd89a175486d21d2bb2efabc91 (\u001b[1;31mtestbranch\u001b[m) : added hellow world metadata\n",
      "* 4fdb96afed4ec62e9fc80328abccae6bf6774fea : mutated sample `0` of `dummy_dataset` to new value\n",
      "* b21ebbeeece723bf7aa2157eb2e8742a043df7d0 : first commit with a single sample added to a dummy dataset\n"
     ]
    }
   ],
   "source": [
    "repo.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the history of the `\"master\"` branch by specifying it as an argument to the `log()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 0cdd8c833f654d18ddc2b089fabee93c32c9c155 (\u001b[1;31mmaster\u001b[m) (\u001b[1;31mnew\u001b[m) : commit on `new` branch adding a sample to dummy_dataset\n",
      "* b21ebbeeece723bf7aa2157eb2e8742a043df7d0 : first commit with a single sample added to a dummy dataset\n"
     ]
    }
   ],
   "source": [
    "repo.log('master')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging (Part 2) Three Way Merge\n",
    "\n",
    "If we now want to merge the changes on `\"testbranch\"` into `\"master\"`, we can't just follow a simple linear history; **the branches have diverged**. \n",
    "\n",
    "For this case, Hangar implements a **Three Way Merge** algorithm which does the following:\n",
    "- Find the most recent common ancestor `commit` present in both the `\"testbranch\"` and `\"master\"` branches\n",
    "- Compute what changed between the common ancestor and each branch's `HEAD` commit\n",
    "- Check if any of the changes conflict with eachother (more on this in a later tutorial)\n",
    "- If no conflicts are present, compute the results of the merge between the two sets of changes\n",
    "- Create a new `commit` containing the merge results reference both branch `HEAD`s as parents of the new `commit`, and update the `base` branch `HEAD` to that new `commit`'s `commit_hash`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = repo.checkout(write=True, branch_name='master')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, as a user, the details are completly irrelevent, and the operation occurs from the same one-liner call we used before for the FF Merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 3-Way Merge Strategy\n",
      "(410, 293, 410)\n",
      "removing all stage hash records\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dea1aa627933b3efffa03c743c201ee1b41142c8'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.merge(message='merge of testbranch into master', dev_branch='testbranch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now look at the log, we see that this has a much different look then before. The three way merge results in a history which references changes made in both diverged branches, and unifies them in a single `commit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*   dea1aa627933b3efffa03c743c201ee1b41142c8 (\u001b[1;31mmaster\u001b[m) : merge of testbranch into master\n",
      "\u001b[1;31m|\u001b[m\u001b[1;32m\\\u001b[m  \n",
      "\u001b[1;31m|\u001b[m * ce8a9198d638b8fd89a175486d21d2bb2efabc91 (\u001b[1;31mtestbranch\u001b[m) : added hellow world metadata\n",
      "\u001b[1;31m|\u001b[m * 4fdb96afed4ec62e9fc80328abccae6bf6774fea : mutated sample `0` of `dummy_dataset` to new value\n",
      "* \u001b[1;32m|\u001b[m 0cdd8c833f654d18ddc2b089fabee93c32c9c155 (\u001b[1;31mnew\u001b[m) : commit on `new` branch adding a sample to dummy_dataset\n",
      "\u001b[1;32m|\u001b[m\u001b[1;32m/\u001b[m  \n",
      "* b21ebbeeece723bf7aa2157eb2e8742a043df7d0 : first commit with a single sample added to a dummy dataset\n"
     ]
    }
   ],
   "source": [
    "repo.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually inspecting the merge result to verify it matches our expectations\n",
    "\n",
    "`dummy_dataset` should contain two arrays, key `1` was set in the previous commit originally made in `\"new\"` and merged into `\"master\"`. Key `0` was mutated in `\"testbranch\"` and unchanged in `\"master\"`, so the update from `\"testbranch\"` is kept. \n",
    "\n",
    "There should be one metadata sample with they key `\"hello\"` and the value `\"world\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " Hangar Datasets                \n",
       "     Writeable: True                \n",
       "     Dataset Names:                \n",
       "       - dummy_dataset"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " Hangar DatasetDataWriter                 \n",
       "    Dataset Name     : dummy_dataset                \n",
       "    Schema UUID      : d82cddc07e0211e9a08a8c859047adef                \n",
       "    Schema Hash      : 43edf7aa314c                \n",
       "    Variable Shape   : False                \n",
       "    (max) Shape      : (10,)                \n",
       "    Datatype         : <class 'numpy.uint16'>                \n",
       "    Named Samples    : True                \n",
       "    Access Mode      : a                \n",
       "    Num Samples      : 2\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.datasets['dummy_dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50, 51, 52, 53, 54, 55, 56, 57, 58, 59], dtype=uint16)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.datasets['dummy_dataset']['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint16)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.datasets['dummy_dataset']['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " Hangar Metadata                \n",
       "     Writeable: True                \n",
       "     Number of Keys: 1\n"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'world'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.metadata['hello']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Merge was a success!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writer checkout of master closed\n"
     ]
    }
   ],
   "source": [
    "co.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conflicts\n",
    "\n",
    "Now that we've seen merging in action, the next step is to talk about conflicts. \n",
    "\n",
    "### How Are Conflicts Detected?\n",
    "\n",
    "Any merge conflicts can be identified and addressed ahead of running a ``merge`` command by using the built in ``diff`` tools. When diffing commits, Hangar will provide a list of conflicts which it identifies. In general these fall into 4 catagories:\n",
    "\n",
    "1. **Additions** in both branches which created new keys (samples / datasets / metadata) with non-compatible values. For samples & metadata, the hash of the data is compared, for datasets, the schema specification is checked for compatibility in a method custom to the internal workings of Hangar.\n",
    "2. **Removal** in ``Master Commit/Branch`` **& Mutation** in ``Dev Commit/Branch``. Applies for samples, datasets, and metadata identically.\n",
    "3. **Mutation** in ``Dev Commit/Branch`` **& Removal** in ``Master Commit/Branch``. Applies for samples, datasets, and metadata identically.\n",
    "4. **Mutations** on keys both branches to non-compatible values. For samples & metadata, the hash of the data is compared, for datasets, the schema specification is checked for compatibility in a method custom to the internal workings of Hangar.\n",
    "\n",
    "### Let's make a merge conflict\n",
    "\n",
    "To force a conflict, we are going to checkout the `\"new\"` branch and set the metadata key `\"hello\"` to the value `\"foo conflict... BOO!\"`. If we then try to merge this into the `\"testbranch\"` branch (which set `\"hello\"` to a value of `\"world\"`) we see how hangar will identify the conflict and halt without making any changes. \n",
    "\n",
    "Automated conflict resolution will be introduced in a future version of Hangar, for now it is up to the user to manually resolve conflicts by making any necessary changes in each branch before reattempting a merge operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = repo.checkout(write=True, branch_name='new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "co.metadata['hello'] = 'foo conflict... BOO!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commit operation requested with message: commit on new branch to hello metadata key so we can demonstrate a conflict\n",
      "(410, 294, 410)\n",
      "removing all stage hash records\n",
      "Commit completed. Commit hash: 5e76faba059c156bc9ed181446e104765cb471c3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'5e76faba059c156bc9ed181446e104765cb471c3'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.commit ('commit on new branch to hello metadata key so we can demonstrate a conflict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 5e76faba059c156bc9ed181446e104765cb471c3 (\u001b[1;31mnew\u001b[m) : commit on new branch to hello metadata key so we can demonstrate a conflict\n",
      "* 0cdd8c833f654d18ddc2b089fabee93c32c9c155 : commit on `new` branch adding a sample to dummy_dataset\n",
      "* b21ebbeeece723bf7aa2157eb2e8742a043df7d0 : first commit with a single sample added to a dummy dataset\n"
     ]
    }
   ],
   "source": [
    "repo.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When we attempt the merge, an exception is thrown telling us there is a conflict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 3-Way Merge Strategy\n",
      "HANGAR VALUE ERROR:: Merge ABORTED with conflict: {'dset': ConflictRecords(t1=(), t21=(), t22=(), t3=(), conflict=False), 'meta': ConflictRecords(t1=('hello',), t21=(), t22=(), t3=(), conflict=True), 'sample': {'dummy_dataset': ConflictRecords(t1=(), t21=(), t22=(), t3=(), conflict=False)}, 'conflict_found': True}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "HANGAR VALUE ERROR:: Merge ABORTED with conflict: {'dset': ConflictRecords(t1=(), t21=(), t22=(), t3=(), conflict=False), 'meta': ConflictRecords(t1=('hello',), t21=(), t22=(), t3=(), conflict=True), 'sample': {'dummy_dataset': ConflictRecords(t1=(), t21=(), t22=(), t3=(), conflict=False)}, 'conflict_found': True}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-1a98dce1852b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'this merge should not happen'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_branch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'testbranch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/tensorwerk/hangar/hangar-py/src/hangar/checkout.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, message, dev_branch)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mdev_branch_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_branch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mrepo_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repo_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             writer_uuid=self._writer_lock)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdsetHandle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tensorwerk/hangar/hangar-py/src/hangar/merger.py\u001b[0m in \u001b[0;36mselect_merge_algorithm\u001b[0;34m(message, branchenv, stageenv, refenv, stagehashenv, master_branch_name, dev_branch_name, repo_path, writer_uuid)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tensorwerk/hangar/hangar-py/src/hangar/merger.py\u001b[0m in \u001b[0;36mselect_merge_algorithm\u001b[0;34m(message, branchenv, stageenv, refenv, stagehashenv, master_branch_name, dev_branch_name, repo_path, writer_uuid)\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mrefenv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrefenv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0mstagehashenv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstagehashenv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 repo_path=repo_path)\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tensorwerk/hangar/hangar-py/src/hangar/merger.py\u001b[0m in \u001b[0;36m_three_way_merge\u001b[0;34m(message, master_branch_name, masterHEAD, dev_branch_name, devHEAD, ancestorHEAD, branchenv, stageenv, refenv, stagehashenv, repo_path)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mfmtCont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_merge_dict_to_lmdb_tuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatchedRecs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmergeContents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tensorwerk/hangar/hangar-py/src/hangar/merger.py\u001b[0m in \u001b[0;36m_three_way_merge\u001b[0;34m(message, master_branch_name, masterHEAD, dev_branch_name, devHEAD, ancestorHEAD, branchenv, stageenv, refenv, stagehashenv, repo_path)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mmergeContents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compute_merge_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_cont\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maCont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_cont\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmCont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_cont\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdCont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tensorwerk/hangar/hangar-py/src/hangar/merger.py\u001b[0m in \u001b[0;36m_compute_merge_results\u001b[0;34m(a_cont, m_cont, d_cont)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conflict_found'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'HANGAR VALUE ERROR:: Merge ABORTED with conflict: {confs}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;31m# merging: dataset schemas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: HANGAR VALUE ERROR:: Merge ABORTED with conflict: {'dset': ConflictRecords(t1=(), t21=(), t22=(), t3=(), conflict=False), 'meta': ConflictRecords(t1=('hello',), t21=(), t22=(), t3=(), conflict=True), 'sample': {'dummy_dataset': ConflictRecords(t1=(), t21=(), t22=(), t3=(), conflict=False)}, 'conflict_found': True}"
     ]
    }
   ],
   "source": [
    "co.merge(message='this merge should not happen', dev_branch='testbranch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternatively, use the diff methods on a checkout to test for conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_results, conflicts_found = co.diff.branch('testbranch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dset': ConflictRecords(t1=(), t21=(), t22=(), t3=(), conflict=False),\n",
       " 'meta': ConflictRecords(t1=('hello',), t21=(), t22=(), t3=(), conflict=True),\n",
       " 'sample': {'dummy_dataset': ConflictRecords(t1=(), t21=(), t22=(), t3=(), conflict=False)},\n",
       " 'conflict_found': True}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conflicts_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConflictRecords(t1=('hello',), t21=(), t22=(), t3=(), conflict=True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conflicts_found['meta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type codes for a `ConflictRecords` `namedtuple` such as the one we saw:\n",
    "    \n",
    "    ConflictRecords(t1=('hello',), t21=(), t22=(), t3=(), conflict=True)\n",
    "  \n",
    "are as follow:\n",
    "\n",
    "- `t1`: Addition of key in master AND dev with different values.\n",
    "- `t21`: Removed key in master, mutated value in dev.\n",
    "- `t22`: Removed key in dev, mutated value in master.\n",
    "- `t3`: Mutated key in both master AND dev to different values.\n",
    "- `conflict`: Bool indicating if any type of conflict is present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To resolve, remove the conflict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commit operation requested with message: commit which removes conflicting metadata key\n",
      "(413, 296, 413)\n",
      "removing all stage hash records\n",
      "Commit completed. Commit hash: 4f312b10775c2b0ac51b5f284d2f94e9a8548868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4f312b10775c2b0ac51b5f284d2f94e9a8548868'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del co.metadata['hello']\n",
    "co.metadata['resolved'] = 'conflict by removing hello key'\n",
    "co.commit('commit which removes conflicting metadata key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 3-Way Merge Strategy\n",
      "(465, 331, 465)\n",
      "removing all stage hash records\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3550984bd91afe39d9462f7299c2542e7d45444d'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.merge(message='this merge succeeds as it no longer has a conflict', dev_branch='testbranch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*   3550984bd91afe39d9462f7299c2542e7d45444d (\u001b[1;31mnew\u001b[m) : this merge succeeds as it no longer has a conflict\n",
      "\u001b[1;31m|\u001b[m\u001b[1;32m\\\u001b[m  \n",
      "* \u001b[1;32m|\u001b[m 4f312b10775c2b0ac51b5f284d2f94e9a8548868 : commit which removes conflicting metadata key\n",
      "* \u001b[1;32m|\u001b[m 5e76faba059c156bc9ed181446e104765cb471c3 : commit on new branch to hello metadata key so we can demonstrate a conflict\n",
      "\u001b[1;32m|\u001b[m * ce8a9198d638b8fd89a175486d21d2bb2efabc91 (\u001b[1;31mtestbranch\u001b[m) : added hellow world metadata\n",
      "\u001b[1;32m|\u001b[m * 4fdb96afed4ec62e9fc80328abccae6bf6774fea : mutated sample `0` of `dummy_dataset` to new value\n",
      "* \u001b[1;32m|\u001b[m 0cdd8c833f654d18ddc2b089fabee93c32c9c155 : commit on `new` branch adding a sample to dummy_dataset\n",
      "\u001b[1;32m|\u001b[m\u001b[1;32m/\u001b[m  \n",
      "* b21ebbeeece723bf7aa2157eb2e8742a043df7d0 : first commit with a single sample added to a dummy dataset\n"
     ]
    }
   ],
   "source": [
    "repo.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
