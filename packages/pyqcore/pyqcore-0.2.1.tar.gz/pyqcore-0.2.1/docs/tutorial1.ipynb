{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyQCore Tutorial  \n",
    "  \n",
    "This tutorial is for PyQCore Library.  \n",
    "In this tutorial, we use Japanese Vowels Data Set hosted by UCI.  \n",
    "    https://archive.ics.uci.edu/ml/datasets/Japanese+Vowels  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pyqcore.client import SimpleQCoreClient\n",
    "from pyqcore.examples.jpvow import load_jpvow\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first load data and split them for training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_jpvow()\n",
    "    # Train: 80% / Test: 20%\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    data.data, data.target, test_size=0.2, random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create an API instance and get access token. Make sure that you need get license code from [QuantumCore Website](https://www.qcore.co.jp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===QCORE(Sample)===\n",
      "{'access_token':}\n"
     ]
    }
   ],
   "source": [
    "print(\"===QCORE(Sample)===\")\n",
    "# create API instance\n",
    "client = SimpleQCoreClient()\n",
    "# get token (login)\n",
    "access_token = client.login(\n",
    "         username=\"#USER#\", password=\"#PASS#\", endpoint=\"http://#ENDPOINT#\"\n",
    ")\n",
    "print(access_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for training and classification.  \n",
    "Our engine adopts Rest-API interface, and SimpleQCoreClient makes it easy to convert data to json format and send it to the engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 29, 12)\n",
      "{'res': 'ok', 'train_time': 0.03760866324106852}\n",
      "{'accuracy': 0.9921875, 'f1': 0.9922010869565218, 'res': 'ok'}\n",
      "acc= 0.9921875\n",
      "f1= 0.9922010869565218\n",
      "elapsed_time:3.912313938140869[sec]\n",
      "[5, 9, 7, 1, 3, 3, 4, 9, 9, 3, 8, 2, 1, 6, 9, 7, 3, 4, 6, 9, 1, 4, 8, 1, 8, 3, 7, 7, 8, 4, 8, 4, 7, 2, 6, 7, 3, 9, 4, 2, 8, 3, 7, 6, 5, 4, 2, 1, 8, 7, 2, 7, 3, 6, 5, 2, 5, 7, 1, 4, 2, 4, 8, 2, 1, 1, 8, 9, 3, 7, 4, 6, 8, 8, 3, 7, 3, 1, 6, 2, 3, 8, 7, 9, 8, 3, 7, 2, 4, 5, 3, 2, 6, 3, 5, 8, 3, 8, 6, 9, 8, 3, 6, 1, 9, 2, 3, 7, 6, 3, 4, 9, 5, 8, 8, 3, 3, 3, 1, 8, 5, 3, 9, 4, 7, 4, 1, 8]\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "start = time.time()\n",
    "print(X_train.shape)\n",
    "res = client.classifier_train(X=X_train, Y=y_train, access_token=access_token)\n",
    "print(res)\n",
    "\n",
    "# test\n",
    "res = client.classifier_test(X=X_test, Y=y_test, access_token=access_token)\n",
    "print(res)\n",
    "    \n",
    "# classify\n",
    "res = client.classifier_predict(X=X_test, access_token=access_token)\n",
    "print(\"acc=\", accuracy_score(y_test.tolist(), res[\"Y\"]))\n",
    "print(\"f1=\", f1_score(y_test.tolist(), res[\"Y\"], average=\"weighted\"))\n",
    "elapsed_time = time.time() - start\n",
    "print(\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "\n",
    "print(res['Y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, you can check the softmax values of the prediction with `softmax_top` option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[5, 0.24700839817523956],\n",
       "  [6, 0.08750557154417038],\n",
       "  [8, 0.08679292351007462]],\n",
       " [[9, 0.20201803743839264],\n",
       "  [5, 0.09666953980922699],\n",
       "  [4, 0.09265950322151184]],\n",
       " [[7, 0.2048064023256302], [1, 0.10610369592905045], [8, 0.09740772098302841]]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = client.classifier_predict(X=X_test, access_token=access_token, softmax_top=3)\n",
    "res['Y'][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that our model is currently running on AWS t2.micro instace. In other words, this model runs with tiny CPU, memory and no GPU ([check out the spec here](https://aws.amazon.com/ec2/instance-types/)).  \n",
    "Now let's compare to other model. In this demo, we use Logistic Regression and simple Neural Network(MLP) on Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===LogisticRegression(Using Sklearn)===\n",
      "elapsed_time:0.1754000186920166[sec]\n",
      "acc= 0.9765625\n",
      "f1= 0.9761245153216563\n",
      "===MLP(Using Sklearn)===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time:0.49468994140625[sec]\n",
      "acc= 0.9453125\n",
      "f1= 0.9435481250696572\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(len(X_train), -1).astype(np.float64)\n",
    "X_test = X_test.reshape(len(X_test), -1).astype(np.float64)\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "\n",
    "print(\"===LogisticRegression(Using Sklearn)===\")\n",
    "start = time.time()\n",
    "lr_cls = LogisticRegression(C=9.0)\n",
    "lr_cls.fit(X_train, y_train)\n",
    "elapsed_time = time.time() - start\n",
    "print(\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "res = lr_cls.predict(X=X_test)\n",
    "print(\"acc=\", accuracy_score(y_test.tolist(), res))\n",
    "print(\"f1=\", f1_score(y_test.tolist(), res, average=\"weighted\"))\n",
    "\n",
    "print(\"===MLP(Using Sklearn)===\")\n",
    "start = time.time()\n",
    "mlp_cls = MLPClassifier(hidden_layer_sizes=(100, 100, 100, 10))\n",
    "mlp_cls.fit(X_train, y_train)\n",
    "elapsed_time = time.time() - start\n",
    "print(\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "res = mlp_cls.predict(X=X_test)\n",
    "print(\"acc=\", accuracy_score(y_test.tolist(), res))\n",
    "print(\"f1=\", f1_score(y_test.tolist(), res, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2019 QuantumCore Inc.  \n",
    "Github: [pyqcore](https://github.com/qcore-info/pyqcore)  \n",
    "Web: [QuantumCore Inc.](https://www.qcore.co.jp)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
