{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with L1 penalty (Logistic Lasso)\n",
    "* `sbmi1` -- Logistic Lasso with SAGA solver\n",
    "* `sbmi56` -- Logistic Lasso with liblinear solver\n",
    "* `sbmi57` -- Logistic Lasso with SGD solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add path\n",
    "import sys; import os; sys.path.append(os.path.realpath(\"../\"))\n",
    "\n",
    "# general hyperparameter optimization settings\n",
    "from seasalt import (select_the_best, refit_model) \n",
    "from seasalt.sb import (cv_settings, scorerfun, print_scores)\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo datasets\n",
    "from datasets.demo1 import X_train, Y_train, fold_ids, X_valid, Y_valid, meta as meta_data\n",
    "#meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'sbmi57',\n",
       " 'name': 'Logistic Lasso',\n",
       " 'descriptions': 'Logistic Regression with L1 penalty (Lasso)',\n",
       " 'solver': 'stochastic gradient descent',\n",
       " 'active': True,\n",
       " 'keywords': ['binary classification', 'linear regression'],\n",
       " 'output_num': 'single',\n",
       " 'output_scale': 'binary',\n",
       " 'output_dtype': 'bool',\n",
       " 'input_num': 'multi',\n",
       " 'input_scale': 'interval',\n",
       " 'input_dtype': 'float'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model implementations\n",
    "#from potpourri.sbmi1 import model, hyper, meta  # SAGA\n",
    "#from potpourri.sbmi56 import model, hyper, meta  # liblinear\n",
    "from potpourri.sbmi57 import model, hyper, meta  # SGD\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uh/cfs/venv-3.6.2/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 950 ms, sys: 133 ms, total: 1.08 s\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rscv = RandomizedSearchCV(**{'estimator': model, 'param_distributions': hyper}, **cv_settings)\n",
    "rscv.fit(X = X_train, y = Y_train)  # Run CV\n",
    "\n",
    "bestparam, summary = select_the_best(rscv)  # find the \"best\" parameters\n",
    "bestmodel = refit_model(model, bestparam, X_train, Y_train)  # Refit the \"best\" model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infer/predict on validation set\n",
      "\n",
      "Out of sample score\n",
      "0.9497354497354498\n",
      "\n",
      "Out of sample score (Other metrics)\n",
      "            Matthews: 0.949735\n",
      "           Accurancy: 0.974868\n",
      "             Jaccard: 0.976608\n",
      "             Hamming: 0.023392\n",
      "           Precision: 0.981481\n",
      "              Recall: 0.981481\n",
      "\n",
      "Best model parameters\n",
      "{'lin__alpha': 0.006726403087930424}\n",
      "\n",
      "In-sample scores and model variants (from CV)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lin__alpha</th>\n",
       "      <th>cvratio</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.006726</td>\n",
       "      <td>43.493146</td>\n",
       "      <td>2</td>\n",
       "      <td>0.936219</td>\n",
       "      <td>0.021526</td>\n",
       "      <td>0.098092</td>\n",
       "      <td>0.006162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.003499</td>\n",
       "      <td>43.493146</td>\n",
       "      <td>2</td>\n",
       "      <td>0.936219</td>\n",
       "      <td>0.021526</td>\n",
       "      <td>0.082895</td>\n",
       "      <td>0.003551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005984</td>\n",
       "      <td>43.493146</td>\n",
       "      <td>2</td>\n",
       "      <td>0.936219</td>\n",
       "      <td>0.021526</td>\n",
       "      <td>0.135411</td>\n",
       "      <td>0.026509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.004756</td>\n",
       "      <td>43.493146</td>\n",
       "      <td>2</td>\n",
       "      <td>0.936219</td>\n",
       "      <td>0.021526</td>\n",
       "      <td>0.089709</td>\n",
       "      <td>0.008966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002080</td>\n",
       "      <td>23.960689</td>\n",
       "      <td>1</td>\n",
       "      <td>0.941487</td>\n",
       "      <td>0.039293</td>\n",
       "      <td>0.086847</td>\n",
       "      <td>0.005800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lin__alpha    cvratio  rank_test_score  mean_test_score  std_test_score  \\\n",
       "32    0.006726  43.493146                2         0.936219        0.021526   \n",
       "42    0.003499  43.493146                2         0.936219        0.021526   \n",
       "6     0.005984  43.493146                2         0.936219        0.021526   \n",
       "29    0.004756  43.493146                2         0.936219        0.021526   \n",
       "10    0.002080  23.960689                1         0.941487        0.039293   \n",
       "\n",
       "    mean_fit_time  std_fit_time  \n",
       "32       0.098092      0.006162  \n",
       "42       0.082895      0.003551  \n",
       "6        0.135411      0.026509  \n",
       "29       0.089709      0.008966  \n",
       "10       0.086847      0.005800  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Infer/predict on validation set\")\n",
    "Y_pred = bestmodel.predict(X_valid)\n",
    "\n",
    "print(\"\\nOut of sample score\")\n",
    "print(scorerfun(Y_valid, Y_pred))\n",
    "\n",
    "print(\"\\nOut of sample score (Other metrics)\")\n",
    "print_scores(Y_pred, Y_valid)\n",
    "\n",
    "print(\"\\nBest model parameters\")\n",
    "print(bestparam)\n",
    "\n",
    "print(\"\\nIn-sample scores and model variants (from CV)\")\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.28717298, -0.29776681,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        , -1.51523429,  0.        ,  0.2093156 ,\n",
       "        -1.59999204,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.33102573,\n",
       "        -1.66927594, -0.93170008, -0.4651756 ,  0.        , -0.62009103,\n",
       "         0.        , -0.74006564, -0.08149224, -0.45102008,  0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestmodel.steps[1][1].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug, Memory, Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable             Type                  Data/Info\n",
      "----------------------------------------------------\n",
      "RandomizedSearchCV   ABCMeta               <class 'sklearn.model_sel<...>arch.RandomizedSearchCV'>\n",
      "X_train              ndarray               398x30: 11940 elems, type `float64`, 95520 bytes\n",
      "X_valid              ndarray               171x30: 5130 elems, type `float64`, 41040 bytes\n",
      "Y_pred               ndarray               171: 171 elems, type `int64`, 1368 bytes\n",
      "Y_train              ndarray               398: 398 elems, type `int64`, 3184 bytes\n",
      "Y_valid              ndarray               171: 171 elems, type `int64`, 1368 bytes\n",
      "bestmodel            Pipeline              Pipeline(memory=None,\\n  <...>se=0, warm_start=True))])\n",
      "bestparam            dict                  n=1\n",
      "cv_settings          dict                  n=6\n",
      "fold_ids             ndarray               398: 398 elems, type `int64`, 3184 bytes\n",
      "hyper                dict                  n=1\n",
      "meta                 dict                  n=12\n",
      "meta_data            dict                  n=14\n",
      "model                Pipeline              Pipeline(memory=None,\\n  <...>se=0, warm_start=True))])\n",
      "os                   module                <module 'os' from '/Users<...>6.2/lib/python3.6/os.py'>\n",
      "print_scores         function              <function print_scores at 0x11633c158>\n",
      "refit_model          function              <function refit_model at 0x1128baa60>\n",
      "rscv                 RandomizedSearchCV    RandomizedSearchCV(cv=5, <...>n),\\n          verbose=0)\n",
      "scorerfun            function              <function scorerfun at 0x1145b8f28>\n",
      "select_the_best      function              <function select_the_best at 0x112924510>\n",
      "summary              DataFrame                 lin__alpha    cvratio<...> 0.086847      0.005800  \n",
      "sys                  module                <module 'sys' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "#del summary\n",
    "#locals()\n",
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
